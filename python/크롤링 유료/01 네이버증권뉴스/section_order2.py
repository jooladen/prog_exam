import requests
from bs4 import BeautifulSoup
import re
import json
import urllib.parse

# ì„¹ì…˜ ì½”ë“œì™€ ì„¤ëª…
SECTION_MAP = {
    "pwl_nop": "íŒŒì›Œë§í¬ ê´‘ê³ ",
    "sit_4po": "ì‚¬ì´íŠ¸ ì„¹ì…˜",
    "ugN_gnC": "VIEW - ì¼ë°˜ ë¸”ë¡œê·¸/ì¹´í˜",
    "ugB_b1R": "VIEW - ì „ë¬¸ê°€í˜• ë¸”ë¡œê·¸",
    "ugB_qpR": "VIEW - ì¼ë°˜ ë¸”ë¡œê·¸í˜•",
    "ugB_b2R": "VIEW - ì¹´í˜í˜•",
    "kwX_rqT": "ì§€ì‹ë°±ê³¼",
    "ldc_btm": "ë‰´ìŠ¤(ë˜ëŠ” ê¸°íƒ€)",
    "kin": "ì§€ì‹ì¸ (ì§€ì‹iN)",
    "img": "ì´ë¯¸ì§€",
    "web_gen": "ì›¹ì‚¬ì´íŠ¸ ì¼ë°˜ ì˜ì—­ (ì›¹ë¬¸ì„œ)",
    "biz_nop": "ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œí•„"
}

# ì½˜í…ì¸  CSS ì„ íƒì (ì„¹ì…˜ ì½”ë“œë³„)
CONTENT_SELECTOR_MAP = {
    "pwl_nop": "#power_link_body.nad_area ul.lst_type > li",  # ê´‘ê³  ë§í¬
    "sit_4po": "a.total_wrap",           # ì‚¬ì´íŠ¸ ë¸”ë¡
    "ugN_gnC": "a.api_txt_lines.total_tit",  # VIEW ë¸”ë¡œê·¸/ì¹´í˜ ê³µí†µ
    "ugB_b1R": "[data-meta-area='ugB_b1R'] .fds-comps-right-image-text-title",
    "ugB_qpR": "a.api_txt_lines.total_tit",
    "ugB_b2R": "a.api_txt_lines.total_tit",
    "kwX_rqT": "a.total_tit",            # ì§€ì‹ë°±ê³¼
    "ldc_btm": "a.news_tit",             # ë‰´ìŠ¤
    "kin": "a.api_txt_lines.total_tit",  # ì§€ì‹ì¸
    "img": "div.img_area",               # ì´ë¯¸ì§€ ì¸ë„¤ì¼
    "web_gen": "a.total_tit",            # ì›¹ì‚¬ì´íŠ¸
    "biz_nop": "a"                        # ë¹„ì¦ˆ í”„ë¡œí•„
}

def get_section_and_content_counts(keyword):
    enc_keyword = urllib.parse.quote(keyword)
    url = f"https://search.naver.com/search.naver?query={enc_keyword}"

    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')

    script_tags = soup.find_all("script")
    print(f"\nğŸ” ê²€ìƒ‰ì–´: {keyword}\n")
    print("[ë„¤ì´ë²„ ê²€ìƒ‰ ì„¹ì…˜ ìˆœì„œ ë° ì½˜í…ì¸  ìˆ˜]")

    found = False

    for tag in script_tags:
        if 'nx_cr_area_info' in tag.text:
            match = re.search(r'nx_cr_area_info\s*=\s*(\[[^\]]+\])', tag.text)
            if match:
                try:
                    area_list = json.loads(match.group(1))
                    for item in area_list:
                        code = item["n"]
                        desc = SECTION_MAP.get(code, f"ê¸°íƒ€({code})")
                        selector = CONTENT_SELECTOR_MAP.get(code)
                        if selector:
                            count = len(soup.select(selector))
                            print(f"{item['r']:>2}. {desc} ({code}) - ì½˜í…ì¸  {count}ê°œ")
                        else:
                            print(f"{item['r']:>2}. {desc} ({code}) - ì½˜í…ì¸  ìˆ˜ ë¯¸ì§€ì›")
                    found = True
                except Exception as e:
                    print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
                break

    if not found:
        print("âŒ ì„¹ì…˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# âœ… ì‹¤í–‰
get_section_and_content_counts("í¬ë¡¤ë§")
